import{_ as e,c as s,o as a,aj as i}from"./chunks/framework.CSCBGoZg.js";const u=JSON.parse('{"title":"High-Performance Computing (HPC) Comparison","description":"","frontmatter":{},"headers":[],"relativePath":"specs/Comparison/06_High_Performance.md","filePath":"specs/Comparison/06_High_Performance.md"}'),n={name:"specs/Comparison/06_High_Performance.md"};function l(r,t,o,d,h,g){return a(),s("div",null,[...t[0]||(t[0]=[i(`<h1 id="high-performance-computing-hpc-comparison" tabindex="-1">High-Performance Computing (HPC) Comparison <a class="header-anchor" href="#high-performance-computing-hpc-comparison" aria-label="Permalink to “High-Performance Computing (HPC) Comparison”">​</a></h1><p>This document highlights Vex&#39;s unique approach to high-performance computing, focusing on Autonomous Parallelism compared to the manual models of other systems languages.</p><p>Vex is designed with the philosophy that <strong>parallelism should be a compiler optimization, not just a developer burden.</strong></p><table tabindex="0"><thead><tr><th style="text-align:left;">Feature</th><th style="text-align:left;">Vex</th><th style="text-align:left;">Go</th><th style="text-align:left;">Rust</th><th style="text-align:left;">C</th><th style="text-align:left;">C++</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Philosophy</strong></td><td style="text-align:left;"><strong>Autonomous Parallelism</strong></td><td style="text-align:left;">Simplicity / Concurrency</td><td style="text-align:left;">Zero-cost Abstractions</td><td style="text-align:left;">&quot;Close to Metal&quot;</td><td style="text-align:left;">&quot;Do it yourself&quot;</td></tr><tr><td style="text-align:left;"><strong>SIMD Support</strong></td><td style="text-align:left;"><strong>Native &amp; Auto</strong></td><td style="text-align:left;">Assembly (unsafe)</td><td style="text-align:left;">Intrinsics (unsafe) / Portable SIMD</td><td style="text-align:left;">Intrinsics (unsafe)</td><td style="text-align:left;">Intrinsics (unsafe)</td></tr><tr><td style="text-align:left;"><strong>SIMT / GPU</strong></td><td style="text-align:left;"><strong>Native (SPIR-V)</strong></td><td style="text-align:left;">External (CGO/CUDA)</td><td style="text-align:left;">External (wgpu/rust-gpu)</td><td style="text-align:left;">External (CUDA/OpenCL)</td><td style="text-align:left;">External (CUDA/SYCL)</td></tr><tr><td style="text-align:left;"><strong>Scheduler</strong></td><td style="text-align:left;"><strong>M:N (Smart)</strong></td><td style="text-align:left;">M:N (Work Stealing)</td><td style="text-align:left;">1:1 (OS Threads)</td><td style="text-align:left;">1:1 (OS Threads)</td><td style="text-align:left;">1:1 (OS Threads)</td></tr><tr><td style="text-align:left;"><strong>Vectorization</strong></td><td style="text-align:left;">Aggressive Auto-Vectorization</td><td style="text-align:left;">Weak (GC barriers)</td><td style="text-align:left;">Good (LLVM)</td><td style="text-align:left;">Auto (Compiler dependent)</td><td style="text-align:left;">Auto (Compiler dependent)</td></tr><tr><td style="text-align:left;"><strong>Memory Layout</strong></td><td style="text-align:left;">Struct-of-Arrays (SoA) transformations supported</td><td style="text-align:left;">Standard Layout</td><td style="text-align:left;">Standard Layout</td><td style="text-align:left;">Standard Layout</td><td style="text-align:left;">Standard Layout</td></tr></tbody></table><h2 id="_1-autonomous-simt-gpu-offload-via-spir-v" tabindex="-1">1. Autonomous SIMT (GPU Offload) via SPIR-V <a class="header-anchor" href="#_1-autonomous-simt-gpu-offload-via-spir-v" aria-label="Permalink to “1. Autonomous SIMT (GPU Offload) via SPIR-V”">​</a></h2><p>Vex&#39;s killer feature. The compiler analyzes data size and complexity. If the workload surpasses a threshold, it compiles the logic to SPIR-V and dispatches it to the GPU/Compute Device seamlessly.</p><p><strong>Vex:</strong></p><div class="language-rust"><button title="Copy Code" class="copy"></button><span class="lang">rust</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// &#39;data&#39; is 10M elements</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// usage of &#39;gpu&#39; keyword hints preference, or compiler decides</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">fn</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> process</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &amp;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">f32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">..</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        data[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> sin</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data[i]) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> cos</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(data[i]);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p><strong>Others (C++/Rust):</strong> Requires linking against CUDA/OpenCL/Vulkan SDKs, writing separate kernel code (often in a different language/dialect), managing device memory allocation, transfer, and synchronization manually.</p><h2 id="_2-simd-and-auto-vectorization" tabindex="-1">2. SIMD and Auto-Vectorization <a class="header-anchor" href="#_2-simd-and-auto-vectorization" aria-label="Permalink to “2. SIMD and Auto-Vectorization”">​</a></h2><p>While Rust and C++ rely on LLVM&#39;s auto-vectorizer (which is excellent), Vex&#39;s type system is designed to aid vectorization.</p><ul><li><strong>No Aliasing by Default:</strong> Like Fortran, Vex&#39;s strict ownership analysis guarantees non-aliasing pointers in many cases where C/C++ compilers have to be conservative (&quot;maybe-alias&quot;).</li><li><strong>Explicit Alignment:</strong> Types can be naturally aligned for vector registers.</li></ul><h2 id="_3-m-n-scheduler-with-work-awareness" tabindex="-1">3. M:N Scheduler with &quot;Work Awareness&quot; <a class="header-anchor" href="#_3-m-n-scheduler-with-work-awareness" aria-label="Permalink to “3. M:N Scheduler with &quot;Work Awareness&quot;”">​</a></h2><p>Vex&#39;s scheduler is explicitly designed for high-throughput data processing, not just I/O concurrency.</p><ul><li><strong>Blocking I/O:</strong> Handled by efficient epoll/kqueue event loops.</li><li><strong>CPU Bound:</strong> The scheduler partitions large loops into blocks (Tiles) and distributes them across worker threads (M:N), utilizing cache locality. This is similar to what OpenMP does via pragmas (<code>#pragma omp parallel for</code>), but Vex does it <strong>natively and safely</strong> via the Borrow Checker.</li></ul><h2 id="summary" tabindex="-1">Summary <a class="header-anchor" href="#summary" aria-label="Permalink to “Summary”">​</a></h2><ul><li><strong>C/C++</strong> gives you the tools to build a race car, but you have to assemble the engine yourself.</li><li><strong>Rust</strong> gives you a safe chassis, but you still need to install the engine (external crates for async/gpu).</li><li><strong>Go</strong> gives you a minivan—great for carrying people (requests) comfortably, but not for racing (raw compute).</li><li><strong>Vex</strong> is an autonomous electric hypercar. It manages the engine (SIMD), the battery (Memory), and the route (GPU/CPU scheduling) for you, aiming for maximum throughput with safety.</li></ul>`,17)])])}const c=e(n,[["render",l]]);export{u as __pageData,c as default};
